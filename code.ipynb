{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from airflow.operators.python import PythonOperator\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Remove extra whitespace and newline characters\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Function to extract data from a website\n",
    "def extract_data(url):\n",
    "    # Configure Chrome options to run headless\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    \n",
    "    # Using Selenium to load the webpage and wait for dynamic content to load\n",
    "    driver = webdriver.Chrome(options=chrome_options)  # You need to have Chrome WebDriver installed.\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Get the page source after waiting for a while to ensure content loads\n",
    "    driver.implicitly_wait(10)  # Wait for 10 seconds\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # Extract titles and descriptions\n",
    "    data = []\n",
    "    \n",
    "    # Extract titles from heading tags (h1 to h6)\n",
    "    headings = soup.find_all(re.compile('^h[1-6]$'))\n",
    "    for heading in headings:\n",
    "        title_text = heading.get_text(strip=True)\n",
    "        title = preprocess_text(title_text)\n",
    "        data.append([title, \"No description available\"])  # Append None for description\n",
    "    \n",
    "    # Extract descriptions from paragraph tags (p tags)\n",
    "    paragraphs = soup.find_all('p')\n",
    "    for i, description in enumerate(paragraphs):\n",
    "        description_text = description.get_text(strip=True)\n",
    "        description = preprocess_text(description_text)\n",
    "        if i < len(data):  # Check if corresponding title exists\n",
    "            data[i][1] = description  # Update description in existing data entry\n",
    "    \n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Remove extra whitespace and newline characters\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Function to extract data from a website using Beautiful Soup\n",
    "def extract_data(url):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract titles and descriptions\n",
    "        data = []\n",
    "        \n",
    "        # Extract titles from heading tags (h1 to h6)\n",
    "        headings = soup.find_all(re.compile('^h[1-6]$'))\n",
    "        for heading in headings:\n",
    "            title_text = heading.get_text(strip=True)\n",
    "            title = preprocess_text(title_text)\n",
    "            data.append([title, \"No description available\"])  # Append None for description\n",
    "        \n",
    "        # Extract descriptions from paragraph tags (p tags)\n",
    "        paragraphs = soup.find_all('p')\n",
    "        for i, description in enumerate(paragraphs):\n",
    "            description_text = description.get_text(strip=True)\n",
    "            description = preprocess_text(description_text)\n",
    "            if i < len(data):  # Check if corresponding title exists\n",
    "                data[i][1] = description  # Update description in existing data entry\n",
    "        \n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}\")\n",
    "        return None\n",
    "\n",
    "# Extract data from Dawn.com\n",
    "dawn_data = extract_data(\"https://www.dawn.com/\")\n",
    "dawn_df = pd.DataFrame(dawn_data, columns=['Title', 'Description'])\n",
    "\n",
    "# Extract data from Geo.tv\n",
    "geo_data = extract_data(\"https://www.bbc.com/\")\n",
    "geo_df = pd.DataFrame(geo_data, columns=['Title', 'Description'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dawn Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today's Paper | May 15, 2024</td>\n",
       "      <td>Compunode.com Pvt. Ltd. (www.compunode.com).De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>End of live blog for elections 2024</td>\n",
       "      <td>Copyright © 2024, Dawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scrutiny concludes for nomination papers of 48...</td>\n",
       "      <td>NewsKit Publishing Platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ECP notifies Mahmood Khan as PTI-P chairman</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IHC approves Imran Khan’s bail in £190m corrup...</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Chinese films shine once more at Cannes</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Putin’s visit signifies high level of cooperation</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>China’s Swap Connect further enhanced to promo...</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Chinese films shine once more at Cannes</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Putin’s visit signifies high level of cooperation</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0                         Today's Paper | May 15, 2024   \n",
       "1                  End of live blog for elections 2024   \n",
       "2    Scrutiny concludes for nomination papers of 48...   \n",
       "3          ECP notifies Mahmood Khan as PTI-P chairman   \n",
       "4    IHC approves Imran Khan’s bail in £190m corrup...   \n",
       "..                                                 ...   \n",
       "98             Chinese films shine once more at Cannes   \n",
       "99   Putin’s visit signifies high level of cooperation   \n",
       "100  China’s Swap Connect further enhanced to promo...   \n",
       "101            Chinese films shine once more at Cannes   \n",
       "102  Putin’s visit signifies high level of cooperation   \n",
       "\n",
       "                                           Description  \n",
       "0    Compunode.com Pvt. Ltd. (www.compunode.com).De...  \n",
       "1                               Copyright © 2024, Dawn  \n",
       "2                          NewsKit Publishing Platform  \n",
       "3                             No description available  \n",
       "4                             No description available  \n",
       "..                                                 ...  \n",
       "98                            No description available  \n",
       "99                            No description available  \n",
       "100                           No description available  \n",
       "101                           No description available  \n",
       "102                           No description available  \n",
       "\n",
       "[103 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataframes of both sources before combining\n",
    "print(\"Dawn Data:\")\n",
    "\n",
    "dawn_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BBC Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slovak PM Robert Fico carried to car after bei...</td>\n",
       "      <td>PM Robert Fico was shot in what the Slovak Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crew trapped on Baltimore ship, weeks after br...</td>\n",
       "      <td>Morale is low for the Dali's crew members, who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Slovak PM Robert Fico carried to car after bei...</td>\n",
       "      <td>PM Robert Fico was shot in what the Slovak Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crew trapped on Baltimore ship, weeks after br...</td>\n",
       "      <td>Morale is low for the Dali's crew members, who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Slovak PM in life-threatening condition after ...</td>\n",
       "      <td>Robert Fico was shot as he left a meeting in H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Travel</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>An F1-fanatic chef's guide to Emilia-Romagna</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Where do all those Mother's Day flowers come f...</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>The US Founding Father who travelled the globe</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Yosemite's hidden Chinese American history</td>\n",
       "      <td>No description available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    Slovak PM Robert Fico carried to car after bei...   \n",
       "1    Crew trapped on Baltimore ship, weeks after br...   \n",
       "2    Slovak PM Robert Fico carried to car after bei...   \n",
       "3    Crew trapped on Baltimore ship, weeks after br...   \n",
       "4    Slovak PM in life-threatening condition after ...   \n",
       "..                                                 ...   \n",
       "116                                             Travel   \n",
       "117       An F1-fanatic chef's guide to Emilia-Romagna   \n",
       "118  Where do all those Mother's Day flowers come f...   \n",
       "119     The US Founding Father who travelled the globe   \n",
       "120         Yosemite's hidden Chinese American history   \n",
       "\n",
       "                                           Description  \n",
       "0    PM Robert Fico was shot in what the Slovak Int...  \n",
       "1    Morale is low for the Dali's crew members, who...  \n",
       "2    PM Robert Fico was shot in what the Slovak Int...  \n",
       "3    Morale is low for the Dali's crew members, who...  \n",
       "4    Robert Fico was shot as he left a meeting in H...  \n",
       "..                                                 ...  \n",
       "116                           No description available  \n",
       "117                           No description available  \n",
       "118                           No description available  \n",
       "119                           No description available  \n",
       "120                           No description available  \n",
       "\n",
       "[121 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nBBC Data:\")\n",
    "geo_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been stored in 'articles_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Concatenate DataFrames\n",
    "combined_df = pd.concat([dawn_df, geo_df], ignore_index=True)\n",
    "\n",
    "# Remove rows containing '<h1>' to '<h6>' or '<p>' tags in 'Title' or 'Description' columns\n",
    "combined_df = combined_df[~combined_df['Title'].str.contains(r'<h[1-6]>|<p>', regex=True, case=False)]\n",
    "combined_df = combined_df[~combined_df['Description'].str.contains(r'<h[1-6]>|<p>', regex=True, case=False)]\n",
    "\n",
    "# Remove rows with titles having length less than 25\n",
    "combined_df = combined_df[combined_df['Title'].str.len() >= 15]\n",
    "\n",
    "# Drop duplicate rows based on the 'Title' column\n",
    "combined_df.drop_duplicates(subset=['Title'], keep='first', inplace=True)\n",
    "\n",
    "# Reset the index of the combined DataFrame\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "csv_file = \"articles_data.csv\"\n",
    "combined_df.to_csv(csv_file, index=False, encoding='utf-8')\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"Data has been stored in '{csv_file}'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
